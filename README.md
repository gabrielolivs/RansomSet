# RansomSet - A Dataset for Ransomware Detection & Analysis


The following repository represents the entire flow of creation and analysis of the dataset named RansomSet. This study aims to identify crucial features for the early detection of six distinct types of ransomware: WannaCry, Ryuk, CryptoLocker, Conti, Sodinokibi, and LockBit. We used the Cuckoo platform to record and analyze the activities of these ransomwares. Subsequently, we curated specialized datasets for each studied variant, incorporating both normal samples and attack samples corresponding to each ransomware family. Finally, we employed feature selection methods to identify the 20 most representative features in our multiclass datasets, aiming to significantly contribute to the enhancement of ransomware detection mechanisms.

1. Sample JSON file of each binary is generated by [Cuckoo Sandbox](https://cuckoosandbox.org).

To filter and collect the features studied in the work, it is necessary to execute the script created during the study. The Script performs filtering using two main functions that combine it, which are the 'capture_columns' and 'json_arq' functions.

The Python function capture_columns is responsible for processing a list of JSON files, aiming to extract information about system calls (APIs) contained within them. It iterates over each file, loads its content as a JSON object, and then traverses the data structures to identify the APIs used. These APIs are aggregated into a list, ensuring that there are no duplicates. The function handles potential JSON decoding errors, reporting them and continuing with the analysis of the remaining files. At the end of the process, the function returns a consolidated list containing all the unique APIs found in the processed files.

When executed with a list of JSON files as input, capture_columns meticulously scans to capture the relevant features of each file, represented by the system calls present. This process is crucial for subsequent analyses, such as pattern detection or training machine learning models. Therefore, the function plays a fundamental role in data extraction and preparation, providing a solid foundation for future investigations or applications related to cybersecurity.

```py
def captura_colunas(dir_list):
    print("Iniciando a captura de features na função")
    colunas = []
    contador = 0

    for arquivo in dir_list:
        try:
            with open(arquivo, 'r', encoding='utf8') as f:
                data = json.load(f)
                print("Lendo a classe = " + str(data['target']['file']['name']) + " Contador = " + str(contador) + " do arquivo => " + arquivo)
                for i in data['behavior']['processes']:
                    for j in i['calls']:
                        api = j['api']
                        if api not in colunas:
                            colunas.append(api)
                contador += 1
        except json.decoder.JSONDecodeError as e:
            print(f"Erro ao decodificar JSON no arquivo {arquivo}: {e}")
            continue  #-- Continua para o próximo arquivo
    print("Retornando colunas de features!")
    return colunas

```
The json_arq function in Python performs the following tasks:

Initially, it opens a CSV file located in the directory where the files are located in appendix mode, encoding it with 'utf-8'. Initializes a CSV writer object to write to this file. It then writes a header row consisting of timestamp, class, and score_binary, followed by the columns extracted from the JSON data.

Next, for each file in the dir_arq directory list, the function iterates over the JSON content. For each process within the JSON data, it determines the class (either 'Normal' or one of the specified ransomware names) based on the file's name. It extracts the timestamp and the binary score from the JSON data. Then, it counts the occurrences of each API call in the process and writes a row to the CSV file containing the class, score, and the count of each API call.

During execution, it prints informative messages such as the file name being processed, the class being included, and the count of API calls being added to the CSV file.

Overall, this function facilitates the conversion of JSON data into a structured CSV format, capturing essential information about each process and its associated class, score, and API call counts.


```py
def json_arq(dir_arq, colunas):
    with open('C:\\Users\\gabri\\OneDrive\\Área de Trabalho\\Foletto\\QuasarRAT\\Dataset_QuasarRAT.csv', 'a', newline='', encoding='utf-8') as arquivo_csv:
        writer = csv.writer(arquivo_csv)
        col_aux = ['timestamp','classe', 'score_binary']
        writer.writerow(col_aux + colunas)

        for arquivo in dir_arq:
            print("Nome do arquivo: " + arquivo)  # Nome do arquivo
            with open(arquivo, 'r', encoding='utf8') as f:
                data = json.load(f)

                for i, process in enumerate(data['behavior']['processes']):
                    if data['target']['file']['name'] not in ['WannaCry', 'Ryuk', 'LockBit', 'Conti', 'Sodinikibi','CryptoLocker']:
                        classe = 'Normal'
                    else:
                        classe = data['target']['file']['name']
                    timestamp = process['time']
                    print("Incluindo Classe -> " + classe)
                    #-- Score do binário
                    score = data['info']['score']
                    print("========================================")

                    calls = [call['api'] for call in process['calls']]
                    numeros = [calls.count(coluna) for coluna in colunas]

                    print("Incluindo Contagem de chamadas -> " + classe)
                    writer.writerow([classe,score] + numeros)
```

## Starting 

To run the created script, it is recommended to install the [Anaconda](https://www.anaconda.com/products/distribution) software and that the machine you are using has at least 8GB of RAM memory.

The hierarchical structure of the JSON file illustrated in the Figure below is organized into specific specifications for different data sets. Each section is clearly labeled, making malware analysis information easy to identify and interpret. In this study, system calls were used as resources to analyze ransomware behavior. Within the root section, in block 1, the behavior section was selected to capture the data. In this section you will find processes in block 2, which store the executions carried out by each binary during its execution in the Cuckoo Sandbox environment. Additionally, there is a subsection called calls in block 3, which contains all the system calls made by the binary during its execution.

Each system call in the calls section is identified by an integer from 0 to N in block 5, with N being the total number of system calls performed per binary. This value can be significantly high, exceeding 1,000 or even 10,000 calls. Within each system call, the names of the APIs invoked during the malware's operation are recorded. These names are collected and counted on the first occurrence of each API. If there is a subsequent call to the same API, one more is added to the count, allowing evaluation of the number of times the binary has executed that specific system call.

![ca (1)](https://github.com/gabrielolivs/RansomSet/assets/51774020/90bc0c01-727f-4842-8608-5250cedd0a36)

## Dataset Analysis

The dataset generated during the research development possesses an organized structure aimed at facilitating comprehension and utilization of the data. The figure below illustrates the file structure, wherein each line corresponds to an observation, signifying the execution of a distinct malware instance, while the columns delineate the characteristics gathered during said execution. These columns encompass various fields including scores, ransomware classes (where applicable), particulars concerning system calls made by the binaries, and other pertinent aspects crucial for threat identification and classification.

![dataset drawio-corrigido2 (1)](https://github.com/gabrielolivs/RansomSet/assets/51774020/12a47532-d6f9-448b-b4cd-144b0298349d)

## Experimental Evaluation

To evaluate the dataset’s applicability, experiments were conducted using the XGBoost model, due to its high predictive power and explainability compatibility with SHAP (SHapley Additive Explanations).
The objective was to assess the model’s capability in classifying ransomware families and benign samples, as well as to measure the computational benefits of feature selection.

Two versions of the dataset were used:

1. **Full Dataset:** containing all 240 extracted system call features.

2. **IG-Ranked Dataset:** reduced version with only the Top 25 features ranked by Information Gain (IG).

## Model Explainability (SHAP)

To interpret the model’s decisions, the SHAP framework was applied to the XGBoost results. This method computes the contribution of each feature to the final prediction, offering transparency to the machine learning process.

**Most influential system calls include:**

* `NtAllocateVirtualMemory` – Memory allocation events.

* `NtClose` – Handle termination operations.

* `NtTerminateProcess` – Process control and termination.

* `NtOpenKey` / `NtQueryValueKey` – Registry manipulation.

* `SetUnhandledExceptionFilter` – Exception flow control interception.

<img width="430" height="57" alt="image" src="https://github.com/user-attachments/assets/c9318a19-b965-47fc-ac7d-b33561b14ab6" />


## Practical Implications

The RansomSet dataset can be leveraged by both academia and industry.
Its structure and documentation make it a useful tool for several domains:

* **Benchmarking:** Evaluate and compare machine learning models for ransomware detection.

* **Feature Selection Studies:** Test and validate dimensionality reduction methods.

* **Cyber Threat Intelligence:** Identify patterns and operational behaviors of malware families.

* **Educational Use:** Serve as a didactic dataset for cybersecurity courses and labs.

## Limitations

Despite its comprehensiveness, RansomSet has natural limitations that must be considered:

1. Scope: Limited to six ransomware families and 23 benign binaries.

2. Controlled Environment: All samples were analyzed within a single Windows 7 VM instance.

3. Sandbox Evasion: Some ransomware may detect and alter behavior when executed in sandboxed conditions.

Future expansions will aim to include modern operating systems (Windows 10/11) and new ransomware variants, improving diversity and robustness.

## Conclusion and Future Work

The RansomSet dataset was developed to address the lack of modern, explainable, and publicly available ransomware data. By combining dynamic behavioral analysis, Information Gain feature selection, and SHAP-based interpretability, it offers a foundation for reproducible and explainable research in malware detection.

# Key Highlights:

* Public, structured dataset for multiclass ransomware detection.

* Compatible with modern system call environments.

* Achieves 99% F1-score with interpretable features.

* Fully open for replication and extension

## Future Work:

* Integration with **live Intrusion Detection Systems (IDS/EDR)**.

* Addition of **new malware and benign families**.

* Development of **lightweight detection agents** for real-time environments
