# RansomSet - A Dataset for Ransomware Detection & Analysis


The following repository represents the entire flow of creation and analysis of the dataset named RansomSet. This study aims to identify crucial features for the early detection of six distinct types of ransomware: WannaCry, Ryuk, CryptoLocker, Conti, Sodinokibi, and LockBit. We used the Cuckoo platform to record and analyze the activities of these ransomwares. Subsequently, we curated specialized datasets for each studied variant, incorporating both normal samples and attack samples corresponding to each ransomware family. Finally, we employed feature selection methods to identify the 20 most representative features in our multiclass datasets, aiming to significantly contribute to the enhancement of ransomware detection mechanisms.

1. Sample JSON file of each binary is generated by [Cuckoo Sandbox](https://cuckoosandbox.org).

To filter and collect the features studied in the work, it is necessary to execute the script created during the study. The Script performs filtering using two main functions that combine it, which are the 'capture_columns' and 'json_arq' functions.

The Python function capture_columns is responsible for processing a list of JSON files, aiming to extract information about system calls (APIs) contained within them. It iterates over each file, loads its content as a JSON object, and then traverses the data structures to identify the APIs used. These APIs are aggregated into a list, ensuring that there are no duplicates. The function handles potential JSON decoding errors, reporting them and continuing with the analysis of the remaining files. At the end of the process, the function returns a consolidated list containing all the unique APIs found in the processed files.

When executed with a list of JSON files as input, capture_columns meticulously scans to capture the relevant features of each file, represented by the system calls present. This process is crucial for subsequent analyses, such as pattern detection or training machine learning models. Therefore, the function plays a fundamental role in data extraction and preparation, providing a solid foundation for future investigations or applications related to cybersecurity.

```py
def captura_colunas(dir_list):
    print("Iniciando a captura de features na função")
    colunas = []
    contador = 0

    for arquivo in dir_list:
        try:
            with open(arquivo, 'r', encoding='utf8') as f:
                data = json.load(f)
                print("Lendo a classe = " + str(data['target']['file']['name']) + " Contador = " + str(contador) + " do arquivo => " + arquivo)
                for i in data['behavior']['processes']:
                    for j in i['calls']:
                        api = j['api']
                        if api not in colunas:
                            colunas.append(api)
                contador += 1
        except json.decoder.JSONDecodeError as e:
            print(f"Erro ao decodificar JSON no arquivo {arquivo}: {e}")
            continue  #-- Continua para o próximo arquivo
    print("Retornando colunas de features!")
    return colunas

```
The json_arq function in Python performs the following tasks:

Initially, it opens a CSV file located in the directory where the files are located in appendix mode, encoding it with 'utf-8'. Initializes a CSV writer object to write to this file. It then writes a header row consisting of timestamp, class, and score_binary, followed by the columns extracted from the JSON data.

Next, for each file in the dir_arq directory list, the function iterates over the JSON content. For each process within the JSON data, it determines the class (either 'Normal' or one of the specified ransomware names) based on the file's name. It extracts the timestamp and the binary score from the JSON data. Then, it counts the occurrences of each API call in the process and writes a row to the CSV file containing the class, score, and the count of each API call.

During execution, it prints informative messages such as the file name being processed, the class being included, and the count of API calls being added to the CSV file.

Overall, this function facilitates the conversion of JSON data into a structured CSV format, capturing essential information about each process and its associated class, score, and API call counts.


```py
def json_arq(dir_arq, colunas):
    with open('C:\\Users\\gabri\\OneDrive\\Área de Trabalho\\Foletto\\QuasarRAT\\Dataset_QuasarRAT.csv', 'a', newline='', encoding='utf-8') as arquivo_csv:
        writer = csv.writer(arquivo_csv)
        col_aux = ['timestamp','classe', 'score_binary']
        writer.writerow(col_aux + colunas)

        for arquivo in dir_arq:
            print("Nome do arquivo: " + arquivo)  # Nome do arquivo
            with open(arquivo, 'r', encoding='utf8') as f:
                data = json.load(f)

                for i, process in enumerate(data['behavior']['processes']):
                    if data['target']['file']['name'] not in ['WannaCry', 'Ryuk', 'LockBit', 'Conti', 'Sodinikibi','CryptoLocker']:
                        classe = 'Normal'
                    else:
                        classe = data['target']['file']['name']
                    timestamp = process['time']
                    print("Incluindo Classe -> " + classe)
                    #-- Score do binário
                    score = data['info']['score']
                    print("========================================")

                    calls = [call['api'] for call in process['calls']]
                    numeros = [calls.count(coluna) for coluna in colunas]

                    print("Incluindo Contagem de chamadas -> " + classe)
                    writer.writerow([classe,score] + numeros)
```

## Starting 

To run the created script, it is recommended to install the [Anaconda](https://www.anaconda.com/products/distribution) software and that the machine you are using has at least 8GB of RAM memory.

The hierarchical structure of the JSON file illustrated in the Figure below is organized into specific specifications for different data sets. Each section is clearly labeled, making malware analysis information easy to identify and interpret. In this study, system calls were used as resources to analyze ransomware behavior. Within the root section, in block 1, the behavior section was selected to capture the data. In this section you will find processes in block 2, which store the executions carried out by each binary during its execution in the Cuckoo Sandbox environment. Additionally, there is a subsection called calls in block 3, which contains all the system calls made by the binary during its execution.

Each system call in the calls section is identified by an integer from 0 to N in block 5, with N being the total number of system calls performed per binary. This value can be significantly high, exceeding 1,000 or even 10,000 calls. Within each system call, the names of the APIs invoked during the malware's operation are recorded. These names are collected and counted on the first occurrence of each API. If there is a subsequent call to the same API, one more is added to the count, allowing evaluation of the number of times the binary has executed that specific system call.

![image]()
